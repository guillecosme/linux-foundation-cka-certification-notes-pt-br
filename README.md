
# üìò CKA - Resumo Completo de Prepara√ß√£o

Este documento cont√©m uma revis√£o detalhada dos principais t√≥picos cobrados no exame **KCNA (Kubernetes and Cloud Native Associate)**, com explica√ß√µes, exemplos, comandos √∫teis e links para a documenta√ß√£o oficial.

---

# Componentes

# üìò CKA Study Guide ‚Äì Component Maintenance

## üîπ Introdu√ß√£o
Neste guia vamos detalhar **atualiza√ß√µes e manuten√ß√µes** dos principais componentes de um cluster Kubernetes:
- kube-apiserver
- kube-controller-manager
- kube-scheduler
- kubelet
- kube-proxy
- kubectl
- etcd

Documenta√ß√£o oficial:
- [Cluster Components](https://kubernetes.io/docs/concepts/overview/components/)

---

## üõ†Ô∏è Componentes

### 1. kube-apiserver
- **Fun√ß√£o:**
    - √â o **ponto central de comunica√ß√£o** do cluster.
    - Todos os comandos `kubectl` e intera√ß√µes de componentes passam pelo API Server.
    - Respons√°vel por validar requisi√ß√µes, autenticar usu√°rios e expor a API REST.

- **Manuten√ß√£o:**
    - Monitorar logs e checar conectividade com `kubectl`.
    - Escalar r√©plicas em ambientes com HA.

- **Atualiza√ß√£o:**
    - Em clusters `kubeadm`, o upgrade √© feito com:
      ```bash
      kubeadm upgrade apply v1.30.0
      ```
    - O Pod do `kube-apiserver` √© recriado no namespace `kube-system`.

- **Logs:**
  ```bash
  kubectl -n kube-system logs kube-apiserver-<node-name>
  ```

- **Documenta√ß√£o:**  
  [kube-apiserver](https://kubernetes.io/docs/reference/command-line-tools-reference/kube-apiserver/)

---

### 2. kube-controller-manager
- **Fun√ß√£o:**
    - Executa **control loops** que monitoram o estado do cluster e garantem que o estado atual se alinhe ao desejado.
    - Inclui controladores de replica√ß√£o, endpoints, namespaces, etc.

- **Manuten√ß√£o:**
    - Monitorar logs para identificar falhas em control loops.
    - Garantir alta disponibilidade em clusters HA.

- **Atualiza√ß√£o:**
    - Feita com `kubeadm upgrade apply`, que recria o Pod do controller-manager.

- **Logs:**
  ```bash
  kubectl -n kube-system logs kube-controller-manager-<node-name>
  ```

- **Documenta√ß√£o:**  
  [kube-controller-manager](https://kubernetes.io/docs/reference/command-line-tools-reference/kube-controller-manager/)

---

### 3. kube-scheduler
- **Fun√ß√£o:**
    - Respons√°vel por **agendar Pods** em n√≥s dispon√≠veis.
    - Leva em conta afinidades, tolerations, recursos e pol√≠ticas de scheduling.

- **Manuten√ß√£o:**
    - Monitorar logs para problemas de agendamento.
    - Validar eventos do cluster para identificar pods n√£o agendados.

- **Atualiza√ß√£o:**
    - Feita com `kubeadm upgrade apply`, que recria o Pod do scheduler.

- **Logs:**
  ```bash
  kubectl -n kube-system logs kube-scheduler-<node-name>
  ```

- **Documenta√ß√£o:**  
  [kube-scheduler](https://kubernetes.io/docs/reference/command-line-tools-reference/kube-scheduler/)

---

### 4. kubelet
- **Fun√ß√£o:**
    - Agente que roda em cada n√≥.
    - Garante que os Pods definidos pelo API Server estejam rodando no n√≥.
    - Monitora containers via runtime (containerd, cri-o, docker).

- **Manuten√ß√£o:**
    - Reiniciar o servi√ßo se houver falhas:
      ```bash
      sudo systemctl restart kubelet
      ```

- **Atualiza√ß√£o:**
    - Atualizado individualmente em cada n√≥:
      ```bash
      sudo apt-get install -y kubelet=1.30.0-00
      sudo systemctl daemon-reload
      sudo systemctl restart kubelet
      ```

- **Logs:**
  ```bash
  journalctl -u kubelet -f
  ```

- **Documenta√ß√£o:**  
  [kubelet](https://kubernetes.io/docs/reference/command-line-tools-reference/kubelet/)

---

### 5. kube-proxy
- **Fun√ß√£o:**
    - Mant√©m as **regras de rede** em cada n√≥.
    - Implementa balanceamento de carga e roteamento para Services.
    - Pode rodar em modo `iptables` ou `ipvs`.

- **Manuten√ß√£o:**
    - Validar se os Pods `kube-proxy` est√£o rodando como DaemonSet.
    - Analisar logs em caso de falhas de conectividade entre servi√ßos.

- **Atualiza√ß√£o:**
    - Feita atualizando a imagem do DaemonSet:
      ```bash
      kubectl -n kube-system set image ds/kube-proxy       kube-proxy=k8s.gcr.io/kube-proxy:v1.30.0
      ```

- **Logs:**
  ```bash
  kubectl -n kube-system logs -l k8s-app=kube-proxy
  ```

- **Documenta√ß√£o:**  
  [kube-proxy](https://kubernetes.io/docs/reference/command-line-tools-reference/kube-proxy/)

---

### 6. kubectl
- **Fun√ß√£o:**
    - Ferramenta de linha de comando para interagir com o cluster.
    - Usa a API do kube-apiserver.
    - Essencial para administra√ß√£o e troubleshooting.

- **Manuten√ß√£o:**
    - Verificar compatibilidade de vers√£o entre `kubectl` e servidor.

- **Atualiza√ß√£o:**
    - Manual, no host do administrador:
      ```bash
      curl -LO "https://dl.k8s.io/release/$(curl -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"
      chmod +x kubectl && sudo mv kubectl /usr/local/bin/
      ```

- **Logs:**
    - N√£o gera logs pr√≥prios (client-side).

- **Documenta√ß√£o:**  
  [kubectl](https://kubernetes.io/docs/reference/kubectl/)

---

### 7. etcd
- **Fun√ß√£o:**
    - Banco de dados chave/valor distribu√≠do.
    - Armazena o **estado de todo o cluster** (informa√ß√µes de Pods, ConfigMaps, Secrets etc).
    - √â o **componente mais cr√≠tico** do Kubernetes.

- **Manuten√ß√£o:**
    - Realizar backups regulares:
      ```bash
      ETCDCTL_API=3 etcdctl snapshot save /var/lib/etcd/backup.db
      ```
    - Monitorar espa√ßo em disco e lat√™ncia.
    - Usar monitoramento e alertas para detectar corrup√ß√£o ou lentid√£o.

- **Atualiza√ß√£o:**
    - Controlada pelo `kubeadm upgrade apply`, que atualiza o Pod do etcd.
    - Em clusters externos, precisa ser atualizado manualmente:
      ```bash
      sudo apt-get install -y etcd=<version>
      ```

- **Restore:**
  ```bash
  ETCDCTL_API=3 etcdctl snapshot restore /var/lib/etcd/backup.db     --data-dir=/var/lib/etcd-from-backup
  ```

- **Logs:**
  ```bash
  kubectl -n kube-system logs etcd-<node-name>
  ```

- **Documenta√ß√£o:**  
  [Operating etcd](https://kubernetes.io/docs/tasks/administer-cluster/configure-upgrade-etcd/)

---

## üìä Tabela de Manuten√ß√£o e Atualiza√ß√£o por Componente

| Componente            | Fun√ß√£o Principal                          | Logs/Verifica√ß√£o de Status                                        | Atualiza√ß√£o                                        |
|------------------------|-------------------------------------------|-------------------------------------------------------------------|----------------------------------------------------|
| **kube-apiserver**     | Interface central (API REST)              | `kubectl -n kube-system logs kube-apiserver-<node>`               | `kubeadm upgrade apply`                            |
| **controller-manager** | Control loops                             | `kubectl -n kube-system logs kube-controller-manager-<node>`      | `kubeadm upgrade apply`                            |
| **kube-scheduler**     | Agenda Pods nos n√≥s                       | `kubectl -n kube-system logs kube-scheduler-<node>`               | `kubeadm upgrade apply`                            |
| **kubelet**            | Agente nos n√≥s                            | `journalctl -u kubelet -f`                                        | `apt-get install kubelet` + restart                |
| **kube-proxy**         | Regras de rede / Service routing          | `kubectl -n kube-system logs -l k8s-app=kube-proxy`               | Atualizado via DaemonSet (nova imagem)             |
| **kubectl**            | CLI de administra√ß√£o                      | `kubectl version --client --short`                                | Baixar bin√°rio mais recente                        |
| **etcd**               | Banco chave/valor do estado do cluster    | `kubectl -n kube-system logs etcd-<node>`                         | `kubeadm upgrade apply` ou atualiza√ß√£o manual      |

---

## ‚úÖ Resumo
- **etcd** √© o componente mais cr√≠tico ‚Üí sempre mantenha backups.
- **Planos de upgrade (`kubeadm upgrade plan`)** ajudam a atualizar control-plane com seguran√ßa.
- **kubelet** e **kubectl** s√£o atualizados manualmente em cada n√≥/host.
- **kube-proxy** √© atualizado trocando a imagem do DaemonSet.
- Monitorar logs de cada componente √© essencial para troubleshooting.

---

## 1. üîé Core Concepts

### Pods
- Unidade m√≠nima de execu√ß√£o no Kubernetes.  
- Pode conter **um ou mais containers** que compartilham:  
  - Rede (IP, portas)  
  - Volumes (armazenamento)  

**Comandos √∫teis:**
```bash
kubectl run nginx --image=nginx
kubectl get pods
kubectl describe pod <NOME>
```

üëâ [Documenta√ß√£o oficial](https://kubernetes.io/docs/concepts/workloads/pods/)

---

### ReplicaSets
- Garante que o n√∫mero desejado de **r√©plicas de Pods** esteja sempre em execu√ß√£o.  
- Substitu√≠do na pr√°tica por **Deployments**.  

**Exemplo YAML:**
```yaml
apiVersion: apps/v1
kind: ReplicaSet
metadata:
  name: my-replicaset
spec:
  replicas: 3
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx
```

üëâ [Documenta√ß√£o oficial](https://kubernetes.io/docs/concepts/workloads/controllers/replicaset/)

---

### Deployments
- Controla ReplicaSets.  
- Permite **rollouts** (atualiza√ß√µes) e **rollbacks**.  

**Comandos √∫teis:**
```bash
kubectl create deployment nginx --image=nginx
kubectl get deployments
kubectl rollout status deployment/nginx
kubectl rollout history deployment/nginx
kubectl rollout undo deployment/nginx
```

üëâ [Documenta√ß√£o oficial](https://kubernetes.io/docs/concepts/workloads/controllers/deployment/)

---

### Services
- Abstra√ß√£o de rede que exp√µe Pods.  
- Tipos principais:  
  - **ClusterIP** (interno, padr√£o)  
  - **NodePort** (exposi√ß√£o em portas do Node)  
  - **LoadBalancer** (integra com nuvem)  

**Comandos √∫teis:**
```bash
kubectl expose deployment nginx --port=80 --target-port=80 --type=ClusterIP
kubectl expose deployment nginx --type=NodePort --port=80
kubectl get svc
```

üëâ [Documenta√ß√£o oficial](https://kubernetes.io/docs/concepts/services-networking/service/)

---

### Namespaces
- Isolam recursos dentro de um cluster.  
- Muito usados em multi-tenant clusters.  

**Comandos √∫teis:**
```bash
kubectl get namespaces
kubectl create namespace dev
kubectl get pods -n dev
```

üëâ [Documenta√ß√£o oficial](https://kubernetes.io/docs/concepts/overview/working-with-objects/namespaces/)

---

### ConfigMaps e Secrets
- **ConfigMaps**: armazenam configura√ß√µes n√£o sens√≠veis.  
- **Secrets**: armazenam informa√ß√µes sens√≠veis (base64).  

**Comandos √∫teis:**
```bash
kubectl create configmap app-config --from-literal=ENV=prod
kubectl get configmap app-config -o yaml

kubectl create secret generic db-secret --from-literal=PASSWORD=12345
kubectl get secret db-secret -o yaml
```

üëâ [ConfigMaps](https://kubernetes.io/docs/concepts/configuration/configmap/)  
üëâ [Secrets](https://kubernetes.io/docs/concepts/configuration/secret/)

---

## 2. ‚öñÔ∏è Scheduling & Workload Management

### Requests e Limits
- **Requests**: recursos m√≠nimos garantidos.  
- **Limits**: m√°ximo permitido.  

**Exemplo YAML:**
```yaml
resources:
  requests:
    memory: "512Mi"
    cpu: "500m"
  limits:
    memory: "1Gi"
    cpu: "1"
```

üëâ [Documenta√ß√£o oficial](https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/)

---

### LimitRange
Define valores padr√µes e limites m√≠nimos/m√°ximos.  

**Exemplo:**
```yaml
apiVersion: v1
kind: LimitRange
metadata:
  name: cpu-limit-range
spec:
  limits:
  - default:
      cpu: 500m
    defaultRequest:
      cpu: 200m
    max:
      cpu: "1"
    min:
      cpu: 100m
    type: Container
```

üëâ [Documenta√ß√£o oficial](https://kubernetes.io/docs/concepts/policy/limit-range/)

---

### ResourceQuota
Limita os recursos **totais do namespace**.  

**Exemplo:**
```yaml
apiVersion: v1
kind: ResourceQuota
metadata:
  name: compute-resources
spec:
  hard:
    requests.cpu: "1"
    requests.memory: 1Gi
    limits.cpu: "2"
    limits.memory: 2Gi
```

üëâ [Documenta√ß√£o oficial](https://kubernetes.io/docs/concepts/policy/resource-quotas/)

---

### DaemonSets
- Garante **1 Pod por Node**.  
- Usado para monitoramento, CNI, proxies.  

**Comandos √∫teis:**
```bash
kubectl get daemonsets
kubectl describe daemonset <NOME>
```

üëâ [Documenta√ß√£o oficial](https://kubernetes.io/docs/concepts/workloads/controllers/daemonset/)

---

### Static Pods
- Gerenciados diretamente pelo **kubelet**.  
- Manifestos em `/etc/kubernetes/manifests/`.  

üëâ [Documenta√ß√£o oficial](https://kubernetes.io/docs/tasks/configure-pod-container/static-pod/)

---

### PriorityClasses
- Define prioridade para Pods.  
- Pods de menor prioridade podem ser **preemptados**.  

**Exemplo:**
```yaml
apiVersion: scheduling.k8s.io/v1
kind: PriorityClass
metadata:
  name: high-priority
value: 100000
globalDefault: false
description: "High priority pods"
```

üëâ [Documenta√ß√£o oficial](https://kubernetes.io/docs/concepts/scheduling-eviction/pod-priority-preemption/)

---

### Admission Controllers
- Validam ou modificam requests para o API Server.  
- Tipos:  
  - **ValidatingWebhook** (somente valida)  
  - **MutatingWebhook** (pode alterar objetos)  

üëâ [Documenta√ß√£o oficial](https://kubernetes.io/docs/reference/access-authn-authz/admission-controllers/)

---

## 3. üìä Escalabilidade

### Horizontal Pod Autoscaler (HPA)
- Escala **horizontalmente** (r√©plicas de Pods).  
- Baseado em m√©tricas (CPU, mem√≥ria ou customizadas).  

**Exemplo:**
```bash
kubectl autoscale deployment nginx --cpu-percent=50 --min=1 --max=5
```

üëâ [Documenta√ß√£o oficial](https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/)

---

### Vertical Pod Autoscaler (VPA)
- Ajusta automaticamente requests/limits de CPU e mem√≥ria.  
- Melhor para workloads **est√°veis**.  

üëâ [Documenta√ß√£o oficial](https://github.com/kubernetes/autoscaler/tree/master/vertical-pod-autoscaler)

---

## 4. üîé Monitoring

### Metrics Server
- Agrega m√©tricas de recursos de Pods e Nodes.  

**Comandos √∫teis:**
```bash
kubectl top nodes
kubectl top pods
```

üëâ [Documenta√ß√£o oficial](https://github.com/kubernetes-sigs/metrics-server)

---

## 5. üîÑ Application Lifecycle Management

- **Rolling Update** (padr√£o) e **Recreate**.  
- **Rollback** poss√≠vel com `kubectl rollout undo`.  
- **ConfigMaps & Secrets** permitem externalizar configs.  
- **Multi-Container Pods**:  
  - Init Containers  
  - Sidecars  

üëâ [Documenta√ß√£o oficial](https://kubernetes.io/docs/concepts/workloads/controllers/deployment/#strategy)

---

## 6. Cluster Maintenece

### 6.1. Atualiza√ß√£o de Clusters
- **Objetivo:** Garantir que os componentes do cluster estejam atualizados com vers√µes suportadas.
- **Ferramentas comuns:**
    - `kubeadm upgrade`
    - Gerenciadores de cluster (GKE, EKS, AKS ‚Üí upgrades automatizados).
- **Passos t√≠picos em clusters `kubeadm`:**
    1. Planejar a atualiza√ß√£o:
       ```bash
       kubeadm upgrade plan
       ```
    2. Atualizar o plano de controle:
       ```bash
       sudo kubeadm upgrade apply v1.30.0
       ```
    3. Atualizar o `kubelet` em cada n√≥:
       ```bash
       sudo apt-get install -y kubelet=1.30.0-00
       sudo systemctl restart kubelet
       ```
- Documenta√ß√£o: [Upgrading kubeadm clusters](https://kubernetes.io/docs/tasks/administer-cluster/kubeadm/kubeadm-upgrade/)

---

### 6.2. Manuten√ß√£o de N√≥s
- **Cordoning (isolamento):** Evita que novos Pods sejam agendados em um n√≥.
  ```bash
  kubectl cordon <node-name>
  ```
- **Draining (remo√ß√£o controlada):** Remove Pods em execu√ß√£o de forma segura.
  ```bash
  kubectl drain <node-name> --ignore-daemonsets --delete-emptydir-data
  ```
- **Uncordoning (reabilitar agendamento):**
  ```bash
  kubectl uncordon <node-name>
  ```

**Exemplo pr√°tico:**
```bash
# Preparar o n√≥ para manuten√ß√£o
kubectl cordon worker-1

# Mover os pods de forma segura
kubectl drain worker-1 --ignore-daemonsets

# Ap√≥s manuten√ß√£o, reabilitar
kubectl uncordon worker-1
```

---

### 6.3. Logs e Monitoramento de Componentes
- **Verificar estado dos componentes:**
  ```bash
  kubectl get componentstatuses
  ```
- **Logs do kubelet (no host):**
  ```bash
  journalctl -u kubelet -f
  ```
- **Logs de Pods de sistema (exemplo: etcd):**
  ```bash
  kubectl -n kube-system logs etcd-master
  ```

Documenta√ß√£o: [Troubleshooting Clusters](https://kubernetes.io/docs/tasks/debug/)

---

### 6.4. Backup e Restore do etcd
- O **etcd** √© o banco de dados chave/valor que armazena o estado do cluster.
- Fazer backup regular √© cr√≠tico para recupera√ß√£o de desastre.

**Backup do etcd:**
```bash
ETCDCTL_API=3 etcdctl   --endpoints=https://127.0.0.1:2379   --cacert=/etc/kubernetes/pki/etcd/ca.crt   --cert=/etc/kubernetes/pki/etcd/server.crt   --key=/etc/kubernetes/pki/etcd/server.key   snapshot save /var/lib/etcd/backup.db
```

**Restore do etcd:**
```bash
ETCDCTL_API=3 etcdctl snapshot restore /var/lib/etcd/backup.db   --data-dir=/var/lib/etcd-from-backup
```

Documenta√ß√£o: [Operating etcd](https://kubernetes.io/docs/tasks/administer-cluster/configure-upgrade-etcd/)

---

### 6.5. Troubleshooting Comum
- **N√≥ NotReady:**
    - Checar `kubelet` logs.
    - Validar comunica√ß√£o com API Server.
- **Pods presos em Terminating:**
  ```bash
  kubectl delete pod <pod-name> --force --grace-period=0
  ```
- **Erro no etcd:**
    - Validar espa√ßo em disco.
    - Restaurar de snapshot, se necess√°rio.

---

## üìä Tabela de Comandos √öteis de Manuten√ß√£o

| Tarefa                                          | Comando                                                                 |
|-------------------------------------------------|-------------------------------------------------------------------------|
| Planejar upgrade kubeadm                        | `kubeadm upgrade plan`                                                  |
| Aplicar upgrade do cluster                      | `kubeadm upgrade apply vX.Y.Z`                                          |
| Cordon de n√≥  (Deixar o Node fora do scheduler) | `kubectl cordon <node>`                                                 |
| Drain de n√≥                                     | `kubectl drain <node> --ignore-daemonsets --delete-emptydir-data`       |
| Uncordon de n√≥                                  | `kubectl uncordon <node>`                                               |
| Verificar componentes                           | `kubectl get componentstatuses`                                         |
| Logs do kubelet                                 | `journalctl -u kubelet -f`                                              |
| Backup etcd                                     | `etcdctl snapshot save backup.db`                                       |
| Restore etcd                                    | `etcdctl snapshot restore backup.db --data-dir=/var/lib/etcd-from-backup` |
| Verificar estado dos n√≥s                        | `kubectl get nodes -o wide`                                             |
| Checar pods em kube-system                      | `kubectl get pods -n kube-system -o wide`                               |

---

## ‚úÖ Resumo
- Mantenha sempre **backups atualizados do etcd**.
- Use `cordon/drain/uncordon` para manuten√ß√µes seguras.
- Sempre **planeje upgrades** (`kubeadm upgrade plan`).
- Domine **logs e troubleshooting** de componentes cr√≠ticos (`kubelet`, `etcd`, `apiserver`).

---


##  üõ†Ô∏è Tabela de Comandos √öteis

| Objetivo                               | Comando                                         |
|----------------------------------------|-------------------------------------------------|
| Criar recurso a partir de YAML         | `kubectl create -f arquivo.yaml`                |
| Editar Pod                             | `kubectl edit pod <NOME>`                       |
| Deletar Pod                            | `kubectl delete pod <NOME>`                     |
| Criar Deployment                       | `kubectl create deployment nginx --image=nginx` |
| Editar Deployment                      | `kubectl edit deployment <NOME>`                |
| Escalar Deployment                     | `kubectl scale deployment <NOME> --replicas=3`  |
| Atualizar imagem em Deployment         | `kubectl set image deployment/nginx nginx=img:v2` |
| Ver status de rollout                  | `kubectl rollout status deployment/nginx`       |
| Rollback de rollout                    | `kubectl rollout undo deployment/nginx`         |
| Logs de Pod                            | `kubectl logs <POD>`                            |
| Logs de Pod (multi-container)          | `kubectl logs <POD> -c <CONTAINER>`             |
| M√©tricas de Pods                       | `kubectl top pods`                              |
| M√©tricas de Nodes                      | `kubectl top nodes`                             |
| Expor servi√ßo                          | `kubectl expose deployment nginx --port=80`     |

---

## 7. Como fazer a mnuten√ß√£o do Cluster

## üîπ Introdu√ß√£o
Um upgrade de cluster Kubernetes deve ser feito de forma **planejada e ordenada**, garantindo:
- Alta disponibilidade.
- Compatibilidade entre componentes.
- Backups do etcd antes de qualquer a√ß√£o.

Este guia traz um **fluxo passo a passo** para atualizar **control-plane, kubelets, kube-proxy, kubectl e etcd**.

Documenta√ß√£o oficial:
- [Kubeadm upgrade guide](https://kubernetes.io/docs/tasks/administer-cluster/kubeadm/kubeadm-upgrade/)
- [Operating etcd](https://kubernetes.io/docs/tasks/administer-cluster/configure-upgrade-etcd/)

---

## üõ†Ô∏è Checklist Passo a Passo

### 7.1. Pr√©-requisitos
- Backup completo do **etcd**:
  ```bash
  ETCDCTL_API=3 etcdctl snapshot save /var/lib/etcd/backup-$(date +%Y%m%d).db
  ```
- Verificar vers√µes suportadas:
  ```bash
  kubectl version --short
  kubeadm version
  ```
- Checar n√≥s e Pods do sistema:
  ```bash
  kubectl get nodes
  kubectl get pods -n kube-system -o wide
  ```

---

### 7.2. Planejar o Upgrade
```bash
kubeadm upgrade plan
```
- Mostra vers√£o atual, vers√£o alvo e componentes a serem atualizados.

---

### 7.3. Atualizar o Control Plane
1. Atualizar `kubeadm`:
   ```bash
   sudo apt-get install -y kubeadm=1.30.0-00
   ```
2. Aplicar upgrade:
   ```bash
   sudo kubeadm upgrade apply v1.30.0
   ```
3. Atualizar `kubelet` e `kubectl` no n√≥ do control-plane:
   ```bash
   sudo apt-get install -y kubelet=1.30.0-00 kubectl=1.30.0-00
   sudo systemctl daemon-reload
   sudo systemctl restart kubelet
   ```

---

### 7.4. Atualizar os N√≥s Workers
1. Atualizar `kubeadm` no n√≥ worker:
   ```bash
   sudo apt-get install -y kubeadm=1.30.0-00
   ```
2. Colocar o n√≥ em modo manuten√ß√£o:
   ```bash
   kubectl drain <worker-node> --ignore-daemonsets --delete-emptydir-data
   ```
3. Atualizar o n√≥ worker:
   ```bash
   sudo kubeadm upgrade node
   sudo apt-get install -y kubelet=1.30.0-00
   sudo systemctl daemon-reload
   sudo systemctl restart kubelet
   ```
4. Reabilitar o n√≥:
   ```bash
   kubectl uncordon <worker-node>
   ```

---

### 7.5. Atualizar o kube-proxy
- Atualizar imagem do DaemonSet:
  ```bash
  kubectl -n kube-system set image ds/kube-proxy     kube-proxy=k8s.gcr.io/kube-proxy:v1.30.0
  ```

---

### 7.6. Atualizar o kubectl (admin hosts)
- Atualizar bin√°rio no host do administrador:
  ```bash
  curl -LO "https://dl.k8s.io/release/$(curl -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"
  chmod +x kubectl && sudo mv kubectl /usr/local/bin/
  ```

---

### 7.7. Atualizar o etcd
- Em clusters gerenciados por `kubeadm`, o `etcd` √© atualizado junto ao control-plane.
- Para clusters externos (standalone etcd):
  ```bash
  sudo apt-get install -y etcd=<version>
  ```
- Validar integridade ap√≥s upgrade:
  ```bash
  ETCDCTL_API=3 etcdctl endpoint health     --endpoints=https://127.0.0.1:2379     --cacert=/etc/kubernetes/pki/etcd/ca.crt     --cert=/etc/kubernetes/pki/etcd/server.crt     --key=/etc/kubernetes/pki/etcd/server.key
  ```

---

### 7.8. P√≥s-Upgrade (Valida√ß√£o)
- Validar vers√£o do cluster:
  ```bash
  kubectl version --short
  ```
- Verificar componentes:
  ```bash
  kubectl get nodes
  kubectl get pods -n kube-system
  ```
- Verificar etcd:
  ```bash
  kubectl -n kube-system logs etcd-<node-name>
  ```

---

## üìä Resumo do Fluxo
1. **Backup etcd.**
2. Planejar upgrade com `kubeadm upgrade plan`.
3. Atualizar control-plane (`kubeadm`, `kubelet`, `kubectl`).
4. Atualizar workers (drain ‚Üí upgrade ‚Üí uncordon).
5. Atualizar `kube-proxy`.
6. Atualizar `kubectl` nos hosts admin.
7. Atualizar `etcd`.
8. Validar cluster e servi√ßos.

---

## 8 Seguran√ßa em clusters Kubernetes

# üîí CKA Study Guide ‚Äì Seguran√ßa no Kubernetes

## üìò Introdu√ß√£o
Seguran√ßa em Kubernetes √© um dos pilares mais importantes do exame **CKA**. Um administrador precisa entender como proteger o cluster contra acessos indevidos, aplicar controle de permiss√µes, usar certificados, proteger imagens, isolar workloads com pol√≠ticas de rede e manter pr√°ticas seguras no uso de containers.  
Este guia cobre os principais t√≥picos de seguran√ßa exigidos no exame, com explica√ß√µes detalhadas, links para documenta√ß√£o oficial e exemplos pr√°ticos de comandos.

---

## 8.1. üîë Autentica√ß√£o e Autoriza√ß√£o
No Kubernetes, seguran√ßa come√ßa com **quem pode acessar** o cluster (**Autentica√ß√£o**) e **o que pode ser feito** (**Autoriza√ß√£o**).  
A autentica√ß√£o pode ocorrer via certificados x509, tokens de ServiceAccounts, ou integra√ß√£o com provedores externos como OIDC. Ap√≥s autenticado, o request passa por autoriza√ß√£o, onde mecanismos como **RBAC** ou **Webhook Authorizers** decidem se a a√ß√£o √© permitida.  
√â fundamental garantir que usu√°rios humanos usem **credenciais individuais** e workloads usem **ServiceAccounts dedicadas**. Boas pr√°ticas incluem o princ√≠pio de **least privilege** (m√≠nimo de permiss√µes poss√≠veis).

üìñ Doc: [Authentication](https://kubernetes.io/docs/reference/access-authn-authz/authentication/) | [Authorization](https://kubernetes.io/docs/reference/access-authn-authz/authorization/)

**Exemplo:** listar usu√°rios configurados no kubeconfig:
```bash
kubectl config view --minify -o jsonpath='{.users[*].name}'
```

---

## 8.2. üõ°Ô∏è Kubernetes Security Primitives
Kubernetes traz primitivas de seguran√ßa embutidas que permitem isolar workloads e controlar acessos. Entre elas est√£o:
- **Namespaces** para segmenta√ß√£o l√≥gica.
- **RBAC** para gerenciar permiss√µes de usu√°rios e aplica√ß√µes.
- **Network Policies** para restringir tr√°fego entre Pods.
- **ServiceAccounts** que d√£o identidade para workloads.  
  O uso combinado dessas primitivas fornece uma base s√≥lida para segmentar ambientes, aplicar controles granulares e limitar o impacto em caso de comprometimento.

üìñ Doc: [Security Primitives](https://kubernetes.io/docs/concepts/security/)

**Exemplo:** criar namespace isolado para workloads seguros:
```bash
kubectl create namespace secure-apps
```

---

## 8.3. üìú TLS no Kubernetes
### TLS Completo (Sim√©trica, Assim√©trica, CAs, Certificados e Handshake)

### üìö Refer√™ncias Prim√°rias (RFCs e Especifica√ß√µes)
- **TLS 1.3:** RFC 8446 ‚Äî *The Transport Layer Security (TLS) Protocol Version 1.3*
- **TLS 1.2:** RFC 5246 ‚Äî *The Transport Layer Security (TLS) Protocol Version 1.2*
- **X.509 Certs:** RFC 5280 ‚Äî *Internet X.509 Public Key Infrastructure Certificate and CRL Profile*
- **CSR (PKCS #10):** RFC 2986 ‚Äî *Certification Request Syntax Specification (PKCS #10)*
- **Hostname Verification:** RFC 6125 ‚Äî *Service Identity in TLS*

---


### Conceitos de Criptografia

### üîë Criptografia Sim√©trica
- **Uma √∫nica chave secreta** para cifrar e decifrar.
- **Muito r√°pida** (usada para proteger o tr√°fego de dados ap√≥s o handshake).
- Exemplos: **AES-GCM**, **ChaCha20-Poly1305** (ambos AEAD: autenticam e cifram).

```text
[SIM√âTRICA]
Chave Secreta (K)
   |-- Encrypt -->  Ciphertext = ENC_K(plaintext)
   |-- Decrypt -->  Plaintext  = DEC_K(ciphertext)
```

### üîê Criptografia Assim√©trica
- **Par de chaves**: p√∫blica (divulgada) e privada (segredo).
- Mais **lenta**, usada principalmente para **autentica√ß√£o** e **troca de chaves**.
- Exemplos: **RSA**, **ECDSA** (assinatura), **(EC)DHE** (acordo de chaves ef√™meras).

```text
[ASSIM√âTRICA]
Chave P√∫blica do Servidor  -> usada pelo cliente p/ verificar assinatura ou cifrar um segredo
Chave Privada do Servidor  -> usada pelo servidor p/ assinar ou decifrar o segredo
```

### üß™ MAC, AEAD e Integridade
- TLS moderno usa **AEAD** (ex.: AES-GCM, ChaCha20-Poly1305) que prov√™ **confidencialidade + integridade** no mesmo modo.
- Em TLS 1.2, tamb√©m existiam ciphers **MAC-then-Encrypt** (HMAC separado). Em 1.3, apenas **AEAD**.

---

### PKI: Certificados X.509 e CAs

### üèõÔ∏è Cadeia de Confian√ßa
- **Root CA** (autoconfiada) ‚Üí **Intermediate CA** ‚Üí **Certificado do Servidor**.
- Navegadores/SOs confiam nas *Root CAs* pr√©-instaladas e validam a **cadeia**.

```text
+------------------+        +---------------------+        +--------------------------+
| Root CA (self-signed) |->  | Intermediate CA(s) |  ->    | Server Certificate (X.509)|
+------------------+        +---------------------+        +--------------------------+
             Assina                   Assina                       Apresentado no TLS
```

### üìÑ Certificado X.509 (vis√£o geral)
- **Sujeito (Subject)**: identidade (ex.: CN=api.example.com)
- **Emissor (Issuer)**: CA que assinou
- **Validade**: NotBefore / NotAfter
- **Chave P√∫blica** e **Algoritmo de Assinatura**
- **Extens√µes importantes**:
    - **SAN (Subject Alternative Name)** ‚Äî nomes DNS/IP v√°lidos
    - **Key Usage / Extended Key Usage** ‚Äî ex.: TLS Server Auth, Client Auth

### üßæ CSR (PKCS #10)
- Solicita√ß√£o de certificado contendo a **chave p√∫blica** e **provas** de posse da chave privada (assinatura da CSR).

---

### Objetivos do TLS
- **Confidencialidade**: ningu√©m l√™ o tr√°fego.
- **Integridade**: tr√°fego n√£o √© alterado sem detec√ß√£o.
- **Autentica√ß√£o**: cliente confia que fala com o servidor certo (e opcionalmente vice‚Äëversa).
- **Forward Secrecy (PFS)**: segredos de sess√£o passados n√£o s√£o revelados mesmo que a chave privada vaze no futuro (via **(EC)DHE** ef√™mero).

---

### Handshake TLS 1.2 (detalhado)

> TLS 1.2 permite RSA est√°tico para troca de chaves (**sem PFS**) e (EC)DHE (**com PFS**). Aqui focamos no caso **ECDHE** (recomendado).

### üß≠ Fluxo de Mensagens (ECDHE)
```text
Cliente                                                Servidor
   |-- ClientHello (vers√£o, ciphers, curvas, random_C) --->|
   |<-- ServerHello (cipher escolhido, random_S) -----------|
   |<-- Certificate (cadeia do servidor) -------------------|
   |<-- ServerKeyExchange (ECDHE params, assinatura) -------|
   |<-- ServerHelloDone ------------------------------------|
   |-- ClientKeyExchange (ECDHE pub do cliente) ----------->|
   |-- ChangeCipherSpec ----------------------------------->|
   |-- Finished (protegido com chaves derivadas) ---------->|
   |<-- ChangeCipherSpec -----------------------------------|
   |<-- Finished (protegido) -------------------------------|
         [CANAL SIM√âTRICO ATIVO COM AEAD/MAC]
```

### üîß Como as chaves nascem (1.2 com ECDHE)
1. **ECDHE**: cliente e servidor trocam **pontos p√∫blicos**.
2. Cada lado calcula o **segredo compartilhado** `Z = ECDH(priv_local, pub_remoto)`.
3. Deriva‚Äëse o **pre_master_secret** a partir de `Z`.
4. Usa‚Äëse a PRF de TLS 1.2 (HMAC) com `random_C` e `random_S` para gerar o **master_secret**.
5. Do `master_secret` ‚Üí deriva‚Äëse o **key_block** (chaves sim√©tricas + IVs).

```text
ECDHE: Z ---------------> pre_master_secret
pre_master_secret + randoms --PRF--> master_secret
master_secret --PRF--> key_block -> { client_write_key, server_write_key, IVs, ... }
```

### üß© Papel da Assim√©trica vs. Sim√©trica (1.2)
- **Assim√©trica**:
    - O **certificado do servidor** cont√©m a **chave p√∫blica**; o servidor prova posse da privativa ao **assinar** os par√¢metros ECDHE (*ServerKeyExchange*).
    - Opcional: **certificado do cliente** (mTLS).
- **Sim√©trica**:
    - Ap√≥s derivar `key_block`, todo tr√°fego usa **AES-GCM** ou similar (**r√°pido** e eficiente).

---

## Handshake TLS 1.3 (detalhado)

> Simplifica o protocolo, **apenas AEAD**, **apenas (EC)DHE**, **PFS obrigat√≥ria**, **1-RTT** (um ida‚Äëvolta) e otimiza√ß√µes de reuso de sess√£o.

### üß≠ Fluxo de Mensagens (1-RTT)
```text
Cliente                                                Servidor
   |-- ClientHello + KeyShare(C_ECDHE) -------------------->|
   |<-- ServerHello + KeyShare(S_ECDHE) --------------------|
   |<-- EncryptedExtensions --------------------------------|
   |<-- Certificate (opcional p/ server auth) --------------|
   |<-- CertificateVerify ----------------------------------|
   |<-- Finished -------------------------------------------|
   |-- Finished ------------------------------------------->|
        [TR√ÅFEGO APLICACIONAL PROTEGIDO (AEAD)]
```

### üå≤ √Årvore de Segredos (HKDF em 1.3)
- TLS 1.3 usa **HKDF** para deriva√ß√£o: **Early Secret**, **Handshake Secret**, **Master Secret**.
- Acordo ECDHE produz `Z` ‚Üí mistura nos segredos com **salts** e **labels** padronizados ‚Üí gera **traffic secrets**.

```text
          PSK? -> Early Secret
                 |
ECDHE Z ----> Handshake Secret
                 |
             Master Secret
                 |
    +------------+------------+
    |                         |
Handshake Traffic      Application Traffic
Secrets (c/s)          Secrets (c/s)
```

- **Finished** √© calculado com chaves derivadas (garante integridade do handshake).
- **KeyUpdate** permite rotacionar chaves de aplica√ß√£o periodicamente.

### üß© Assim√©trica vs. Sim√©trica (1.3)
- **Assim√©trica**:
    - Autentica√ß√£o do servidor via **Certificate** + **CertificateVerify** (assinatura com chave **privada** do server).
    - Opcionalmente o cliente tamb√©m apresenta certificado (mTLS).
- **Sim√©trica**:
    - Todo tr√°fego p√≥s‚Äëhandshake cifrado via **AEAD** derivado da **Master Secret** (r√°pido e seguro).

---

### mTLS (Mutual TLS)
- Al√©m de o cliente validar o **servidor**, o **servidor tamb√©m valida o cliente**.
- Requer **CA** confi√°vel para os **certificados de cliente** e valida√ß√£o de **Key Usage / EKU** apropriados.

```text
Cliente (cert + chave priv.)  <----TLS---->  Servidor (cert + chave priv.)
          \_________ autentica√ß√£o m√∫tua _______/
```

---

### Resumption e 0-RTT
- **Resumption**: reuso de segredos (via PSK/Tickets) para conex√µes subsequentes mais r√°pidas.
- **0-RTT (TLS 1.3)**: permite enviar dados de aplicativo no *primeiro voo* (antes do Finished), **sujeito a replay**.
    - Use apenas para idempotentes e avalie riscos de repeti√ß√£o.

---

### Compara√ß√£o TLS 1.2 vs TLS 1.3

| Caracter√≠stica             | TLS 1.2                                   | TLS 1.3                                    |
|---------------------------|-------------------------------------------|--------------------------------------------|
| Handshake                 | 2-RTT t√≠pico                              | 1-RTT                                      |
| Troca de chaves           | RSA, DHE, ECDHE (PFS opcional)            | Apenas (EC)DHE (PFS sempre)                 |
| Criptografia              | AEAD e tamb√©m MAC-then-Encrypt            | Apenas AEAD (ex.: AES-GCM, ChaCha20-Poly1305)|
| Seguran√ßa padr√£o          | Algoritmos fracos ainda existem           | Algoritmos fracos removidos                 |
| Resumption                | Session IDs/Tickets                       | PSK/Tickets + 0‚ÄëRTT                         |
| Simplicidade              | Mais complexa                             | Mais simples                                |

---

### Exemplos Pr√°ticos com OpenSSL

### üîé Inspecionar um certificado remoto
```bash
openssl s_client -connect api.example.com:443 -servername api.example.com </dev/null 2>/dev/null | openssl x509 -noout -text
```

### üîó Verificar cadeia e nome do host (RFC 6125)
```bash
openssl s_client -connect api.example.com:443 -servername api.example.com </dev/null \
  | openssl x509 -noout -subject -issuer -dates
openssl s_client -connect api.example.com:443 -servername api.example.com -verify_hostname api.example.com
```

### üßæ Gerar par de chaves e CSR (PKCS#10)
```bash
# Chave privada (ECC P-256)
openssl ecparam -name prime256v1 -genkey -noout -out server.key
# CSR com SAN via config
cat > csr.conf <<'EOF'
[ req ]
prompt = no
distinguished_name = dn
req_extensions = req_ext
[ dn ]
CN = api.example.com
O = Example Org
C = BR
[ req_ext ]
subjectAltName = @alt_names
keyUsage = digitalSignature, keyEncipherment
extendedKeyUsage = serverAuth
[ alt_names ]
DNS.1 = api.example.com
DNS.2 = api.internal
EOF
openssl req -new -key server.key -out server.csr -config csr.conf
```

### üîê For√ßar vers√µes/ciphers em teste
```bash
# TLS 1.3
openssl s_client -tls1_3 -ciphersuites TLS_AES_128_GCM_SHA256 -connect api.example.com:443
# TLS 1.2
openssl s_client -tls1_2 -cipher 'ECDHE+AESGCM' -connect api.example.com:443
```

---

### TLS no Kubernetes

### üîó Onde TLS aparece no K8s
- **kube-apiserver**: apresenta **certificado de servidor** (SAN inclui hostname/IP do API server).
- **kubelet**: autentica‚Äëse ao API usando **certificado de cliente** (mTLS).
- **etcd**: normalmente roda com **certificados de peer** e **server cert** separados (SANs adequados).
- **kube-controller-manager/kube-scheduler**: falam com o API server usando **client certs**.
- **kube-proxy**: tamb√©m se autentica no API server (client cert/token).

```text
   [kubectl] --(TLS/mTLS)--> [kube-apiserver] --(mTLS)--> [etcd]
                 ^                     ^                         ^
                 |                     |                         |
            client cert           server cert/SAN           peer/server certs
```

### üß© Dicas de prova (erros comuns)
- **SAN faltando** no cert do apiserver (ex.: IP do cluster/hostname): conex√µes falham por nome/IP.
- **Key Usage/EKU** incorretos (serverAuth vs clientAuth).
- **Cert expirado** ou **CA errada**.
- **etcd** com **peer cert** incorreto ‚Üí cluster quebra.

### üìÇ Caminhos (kubeadm padr√£o)
```text
/etc/kubernetes/pki/ca.crt
/etc/kubernetes/pki/apiserver.crt
/etc/kubernetes/pki/apiserver.key
/etc/kubernetes/pki/apiserver-kubelet-client.crt
/etc/kubernetes/pki/apiserver-kubelet-client.key
/etc/kubernetes/pki/etcd/ca.crt
/etc/kubernetes/pki/etcd/server.crt
/etc/kubernetes/pki/etcd/server.key
/etc/kubernetes/pki/etcd/peer.crt
/etc/kubernetes/pki/etcd/peer.key
/etc/kubernetes/pki/etcd/healthcheck-client.crt
/etc/kubernetes/pki/etcd/healthcheck-client.key
```

---

## Tabela de Comandos √öteis

| Objetivo | Comando |
|---|---|
| Ver cadeias/vers√µes do servidor | `openssl s_client -connect host:443 -servername host` |
| Mostrar certificado em texto | `... | openssl x509 -noout -text` |
| Verificar SAN/Validade | `openssl x509 -in cert.crt -noout -text` |
| Verificar host (RFC 6125) | `openssl s_client ... -verify_hostname host` |
| Listar ciphers local | `openssl ciphers -v` |
| Testar TLS 1.3 | `openssl s_client -tls1_3 -connect host:443` |
| Testar TLS 1.2 | `openssl s_client -tls1_2 -connect host:443` |
| Gerar key (EC P-256) | `openssl ecparam -name prime256v1 -genkey -noout -out server.key` |
| Criar CSR com SAN | `openssl req -new -key server.key -out server.csr -config csr.conf` |

---

## üîé Vis√£o de Alto N√≠vel: Como TLS usa Sim√©trica + Assim√©trica para assegurar a comunica√ß√£o
1. **Assim√©trica autentica**: o servidor **prova identidade** assinando dados (1.2/1.3) com sua **chave privada**; o cliente valida com a **chave p√∫blica** do certificado (cadeia X.509 verificada at√© uma CA confi√°vel).
2. **(EC)DHE cria segredo ef√™mero**: cliente e servidor trocam valores **p√∫blicos** e cada um calcula o **mesmo segredo compartilhado** `Z` sem transmiti‚Äëlo (Diffie‚ÄëHellman).
3. **HKDF/PRF deriva chaves**: a partir de `Z` e aleat√≥rios do handshake, ambos derivam **segredos de tr√°fego** (sem nunca enviar a chave sim√©trica pela rede).
4. **Sim√©trica protege dados**: com chaves derivadas, o tr√°fego √© cifrado via **AEAD** (r√°pido) garantindo confidencialidade + integridade.
5. **PFS**: como as chaves s√£o ef√™meras, mesmo que a chave privada do servidor vaze, **sess√µes antigas permanecem seguras**.

### Diagrama ASCII Integrado (Linha do Tempo)
```text
Tempo --->

[1] Autentica√ß√£o (Assim√©trica)             [2] Acordo de Chaves (ECDHE)           [3] Tr√°fego (Sim√©trica)
Cliente -----------------------------> Servidor
   |  Recebe Cert (chave p√∫blica)         |  Gera par ECDHE (e assina params)
   |  Verifica cadeia (CA)                |  Envia pub_ECDHE + assinatura
   |  Confia no nome (SAN/Hostname)       |
   |-- envia pub_ECDHE ------------------>|  Calcula Z = ECDH(priv_S, pub_C)
   |  Calcula Z = ECDH(priv_C, pub_S)     |
   |== HKDF/PRF(master/traffic keys) =====|  (mesmo Z, mesmas chaves derivadas)
   |<======== AEAD (dados do app) =======>|  Confidencialidade + Integridade
```

---

### ‚úÖ Conclus√£o
- TLS combina **criptografia assim√©trica** (autentica√ß√£o + acordo) e **sim√©trica** (prote√ß√£o eficiente do tr√°fego) para atingir **confidencialidade, integridade, autentica√ß√£o e PFS**.
- **TLS 1.3** simplifica e fortalece o protocolo, devendo ser a **prefer√™ncia** quando poss√≠vel.
- Para o **CKA**, entenda **cadeias X.509, SANs, EKU/KeyUsage, caminhos de certificados no kubeadm, e como depurar conex√µes** (openssl).

Boa pr√°tica: **automatize a rota√ß√£o** de certificados (apiserver/kubelet/etcd) e **monitore validade** para evitar indisponibilidades.

---

## 8.4. ‚öôÔ∏è KubeConfig
O arquivo `kubeconfig` define como usu√°rios e ferramentas se conectam ao cluster. Ele cont√©m informa√ß√µes como **clusters, usu√°rios, contextos e credenciais**.  
Manter esse arquivo seguro √© fundamental, pois quem tiver acesso pode operar o cluster com as permiss√µes configuradas. Recomenda-se configurar m√∫ltiplos contextos para separar ambientes (dev, stage, prod).  
Al√©m disso, boas pr√°ticas incluem limitar o tempo de validade dos tokens e evitar que chaves privadas fiquem expostas em sistemas de versionamento.

üìñ Doc: [Organizing Cluster Access Using kubeconfig Files](https://kubernetes.io/docs/concepts/configuration/organize-cluster-access-kubeconfig/)

**Exemplo:** trocar contexto ativo para ambiente de produ√ß√£o:
```bash
kubectl config use-context prod-admin
```

---

## 8.5. üìö API Groups
A API do Kubernetes √© dividida em **grupos** que organizam recursos de forma l√≥gica. O grupo **Core (v1)** cont√©m recursos b√°sicos como Pods e Services, enquanto grupos como `apps/v1` e `rbac.authorization.k8s.io/v1` abrangem funcionalidades mais avan√ßadas.  
Entender os grupos de API √© essencial para criar regras de RBAC e YAMLs corretos. Al√©m disso, conhecer as vers√µes dispon√≠veis ajuda a evitar recursos obsoletos.  
Para o exame CKA, √© importante saber diferenciar recursos Core de recursos que pertencem a grupos espec√≠ficos.

üìñ Doc: [Kubernetes API Overview](https://kubernetes.io/docs/reference/using-api/)

**Exemplo:** listar todas as vers√µes de API dispon√≠veis:
```bash
kubectl api-versions
```

---

## 8.6. üë§ RBAC Roles
Roles permitem aplicar permiss√µes dentro de um namespace espec√≠fico. Elas definem quais opera√ß√µes podem ser realizadas em determinados recursos, aplicando granularidade e seguran√ßa.  
Uma Role √© sempre combinada com um **RoleBinding**, que associa a Role a usu√°rios, grupos ou ServiceAccounts. Esse modelo garante que workloads s√≥ consigam executar opera√ß√µes estritamente necess√°rias, reduzindo riscos.  
Sempre aplique o princ√≠pio de ‚Äúmenor privil√©gio‚Äù ao criar Roles.

üìñ Doc: [Using RBAC Authorization](https://kubernetes.io/docs/reference/access-authn-authz/rbac/)

**Exemplo:** Role para leitura de Pods em um namespace:
```yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  namespace: secure-apps
  name: pod-reader
rules:
- apiGroups: [""]
  resources: ["pods"]
  verbs: ["get", "watch", "list"]
```

---

## 8.7. üåê ClusterRoles
Enquanto as Roles se limitam a namespaces, as **ClusterRoles** permitem aplicar permiss√µes em n√≠vel de cluster.  
Elas s√£o √∫teis para recursos que n√£o pertencem a nenhum namespace (como Nodes, PersistentVolumes) ou para fornecer permiss√µes comuns a m√∫ltiplos namespaces.  
Assim como Roles, devem ser usadas em conjunto com um **ClusterRoleBinding**. Um erro comum √© conceder permiss√µes amplas demais em ClusterRoles, aumentando a superf√≠cie de ataque.

üìñ Doc: [ClusterRole and ClusterRoleBinding](https://kubernetes.io/docs/reference/access-authn-authz/rbac/)

**Exemplo:** ClusterRole com acesso de leitura a todos os Nodes:
```yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: node-reader
rules:
- apiGroups: [""]
  resources: ["nodes"]
  verbs: ["get", "list", "watch"]
```

---

## 8.8. üßë‚Äçüíª Service Accounts
ServiceAccounts fornecem identidade para Pods se autenticarem na API.  
Cada Pod por padr√£o recebe uma conta de servi√ßo no namespace default, mas √© uma boa pr√°tica criar ServiceAccounts dedicadas para cada aplica√ß√£o.  
Isso permite aplicar RBAC espec√≠fico para workloads, evitando que aplica√ß√µes tenham mais acesso que o necess√°rio. Tokens de ServiceAccounts podem ser montados como volumes ou injetados automaticamente em Pods.

üìñ Doc: [Configure Service Accounts for Pods](https://kubernetes.io/docs/tasks/configure-pod-container/configure-service-account/)

**Exemplo:** criar uma ServiceAccount:
```bash
kubectl create serviceaccount my-sa -n secure-apps
```

---

## 8.9. üñºÔ∏è Image Security
Manter seguran√ßa em imagens de containers √© essencial. Use sempre imagens de registries confi√°veis, mantenha vers√µes atualizadas e verifique assinaturas quando dispon√≠veis.  
Al√©m disso, configure `imagePullSecrets` para acessar registries privados com seguran√ßa. Ferramentas como Trivy podem ser usadas para escanear imagens em busca de vulnerabilidades.  
Evite usar a tag `latest`, pois isso dificulta auditorias e pode causar inconsist√™ncia entre ambientes.

üìñ Doc: [Image Pull Secrets](https://kubernetes.io/docs/concepts/containers/images/)

**Exemplo:** criar secret para autentica√ß√£o em registry privado:
```bash
kubectl create secret docker-registry regcred   --docker-server=myregistry.io   --docker-username=user   --docker-password=pass   --docker-email=user@example.com
```

---

## 8.10. üê≥ Security nos Docker Containers
Al√©m do Kubernetes, containers precisam de seguran√ßa no n√≠vel do Docker. Boas pr√°ticas incluem:
- Rodar containers como **non-root**.
- Evitar `allowPrivilegeEscalation`.
- Usar `readOnlyRootFilesystem` sempre que poss√≠vel.
- Definir `PodSecurityContext` para grupos e usu√°rios corretos.  
  Essas pr√°ticas reduzem a possibilidade de explora√ß√£o de vulnerabilidades dentro do container.

üìñ Doc: [Pod Security Standards](https://kubernetes.io/docs/concepts/security/pod-security-standards/)

**Exemplo:** rodar Pod como usu√°rio n√£o-root:
```yaml
apiVersion: v1
kind: Pod
metadata:
  name: secure-pod
spec:
  securityContext:
    runAsUser: 1000
    runAsGroup: 3000
    fsGroup: 2000
  containers:
  - name: app
    image: nginx
    securityContext:
      allowPrivilegeEscalation: false
      readOnlyRootFilesystem: true
```

---

## 8.11. üåê Network Policies
As Network Policies permitem restringir tr√°fego de entrada e sa√≠da entre Pods. Sem elas, todo tr√°fego √© permitido por padr√£o.  
Com Network Policies, √© poss√≠vel implementar um modelo de **zero trust**, onde somente comunica√ß√µes explicitamente permitidas ocorrem.  
Elas s√£o aplicadas por namespace e podem controlar tanto tr√°fego **Ingress** quanto **Egress**. Sua efetividade depende do CNI (Container Network Interface) usado no cluster.

üìñ Doc: [Network Policies](https://kubernetes.io/docs/concepts/services-networking/network-policies/)

**Exemplo:** pol√≠tica que permite apenas tr√°fego HTTP do frontend para o backend:
```yaml
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: allow-frontend
  namespace: secure-apps
spec:
  podSelector:
    matchLabels:
      role: backend
  ingress:
  - from:
    - podSelector:
        matchLabels:
          role: frontend
    ports:
    - protocol: TCP
      port: 80
```

---

## 8.12. üîÑ Kubectx e Kubens
Gerenciar m√∫ltiplos clusters e namespaces pode ser confuso. As ferramentas **kubectx** e **kubens** ajudam a alternar rapidamente entre contextos e namespaces.  
Isso reduz erros operacionais, como aplicar comandos em clusters errados. Embora n√£o fa√ßam parte do core do Kubernetes, s√£o ferramentas muito √∫teis no dia a dia de administradores.  
No exame CKA, podem ajudar a ganhar tempo ao alternar ambientes durante os exerc√≠cios pr√°ticos.

üìñ Reposit√≥rio oficial: [ahmetb/kubectx](https://github.com/ahmetb/kubectx)

**Exemplos:**
```bash
# Trocar rapidamente de cluster
kubectx my-cluster

# Trocar de namespace
kubens secure-apps
```

---

## üìä Tabela de Comandos √öteis de Seguran√ßa

| Tarefa                                 | Comando                                                                 |
|----------------------------------------|-------------------------------------------------------------------------|
| Listar usu√°rios configurados           | `kubectl config view --minify -o jsonpath='{.users[*].name}'`           |
| Criar namespace seguro                 | `kubectl create namespace secure-apps`                                  |
| Ver certificados do API Server         | `openssl s_client -connect 127.0.0.1:6443 -showcerts`                   |
| Listar vers√µes de API dispon√≠veis      | `kubectl api-versions`                                                  |
| Criar Service Account                  | `kubectl create serviceaccount my-sa -n secure-apps`                     |
| Criar Secret de registry privado       | `kubectl create secret docker-registry regcred ...`                     |
| Trocar contexto                        | `kubectl config use-context my-context`                                 |
| Trocar cluster com kubectx             | `kubectx my-cluster`                                                    |
| Trocar namespace com kubens            | `kubens secure-apps`                                                    |
| Verificar pods no namespace seguro     | `kubectl get pods -n secure-apps`                                       |

---

## ‚úÖ Resumo
- Entenda profundamente **autentica√ß√£o e autoriza√ß√£o** no Kubernetes.
- Domine **RBAC, Roles e ClusterRoles** para controle de permiss√µes.
- Configure e renove **certificados TLS** corretamente.
- Use **ServiceAccounts** para workloads com permiss√µes m√≠nimas.
- Garanta seguran√ßa em **imagens, pods e containers**.
- Implemente **Network Policies** para isolar workloads.
- Use ferramentas como **kubectx/kubens** para facilitar a administra√ß√£o.

---



## üóÇÔ∏è 9. Storage (Introdu√ß√£o de Storage no Linux)

No Linux, o **storage** √© organizado em um sistema de arquivos hier√°rquico, onde tudo √© tratado como arquivo ou diret√≥rio, incluindo dispositivos de armazenamento. Os dispositivos s√£o montados em pontos de montagem (mount points) para ficarem acess√≠veis no sistema. O kernel gerencia drivers de dispositivos de bloco (block devices), que s√£o usados para armazenar dados de maneira persistente. Parti√ß√µes podem ser criadas para organizar discos, e sistemas de arquivos como **ext4, XFS** s√£o comuns em ambientes Linux. √â importante entender permiss√µes, inodes e links simb√≥licos para administra√ß√£o de volumes. Al√©m disso, conceitos como **LVM (Logical Volume Manager)** permitem flexibilidade para redimensionamento e gerenciamento de discos. Em containers, o sistema de arquivos base do host √© frequentemente usado como camada de persist√™ncia.

**Exemplo:**
```bash
# Listar dispositivos de bloco
lsblk

# Montar manualmente um disco
mount /dev/sdb1 /mnt/data

# Ver espa√ßo em disco
df -h
```

**Refer√™ncias:**
- [Filesystem Hierarchy Standard](https://refspecs.linuxfoundation.org/FHS_3.0/fhs/index.html)
- [Linux Storage Administration](https://tldp.org/HOWTO/LVM-HOWTO/)

---

## 9.1 üê≥ Storage no Docker

O Docker utiliza um sistema de **layers** para armazenar imagens e cont√™ineres. Por padr√£o, o armazenamento √© feito em `/var/lib/docker`. Cada cont√™iner possui um sistema de arquivos baseado em camadas copy-on-write (CoW). Para persistir dados al√©m do ciclo de vida do cont√™iner, o Docker permite o uso de **volumes** e **bind mounts**. Volumes s√£o gerenciados pelo Docker e ficam armazenados no host, enquanto bind mounts mapeiam diret√≥rios do host diretamente no cont√™iner. Volumes s√£o mais recomendados para ambientes de produ√ß√£o, pois s√£o mais port√°veis e independentes da estrutura de diret√≥rios do host.

**Exemplo:**
```bash
# Criar volume
docker volume create meu_volume

# Rodar cont√™iner com volume
docker run -d -v meu_volume:/app/data nginx

# Ver detalhes dos volumes
docker volume inspect meu_volume
```

**Refer√™ncias:**
- [Docker Storage Overview](https://docs.docker.com/storage/)
- [Docker Volumes](https://docs.docker.com/storage/volumes/)

---

## 9.2 üîå Volume Driver Plugin no Docker

O Docker suporta **plugins de volume** para conectar cont√™ineres a sistemas de armazenamento externos como NFS, Ceph, EBS, ou outros provedores de cloud. Drivers podem ser instalados para habilitar funcionalidades avan√ßadas como snapshot, replica√ß√£o ou criptografia. Ao criar volumes com drivers espec√≠ficos, √© poss√≠vel integrar com sistemas de storage corporativos ou cloud providers. √â importante passar op√ß√µes de configura√ß√£o no momento da cria√ß√£o do volume para customizar o comportamento do driver.

**Exemplo:**
```bash
# Criar volume usando driver nfs
docker volume create   --driver local   --opt type=nfs   --opt o=addr=192.168.1.100,rw   --opt device=:/path/to/dir   meu_nfs_volume
```

**Refer√™ncias:**
- [Docker Volume Plugins](https://docs.docker.com/engine/extend/legacy_plugins/)

---

## 9.3 üß© Container Storage Interface (CSI)

O **Container Storage Interface (CSI)** √© um padr√£o que permite que qualquer provedor de armazenamento crie plugins para Kubernetes de forma padronizada. Antes do CSI, existiam drivers embutidos no Kubernetes, o que dificultava a manuten√ß√£o e evolu√ß√£o. Com o CSI, o Kubernetes se torna independente do ciclo de desenvolvimento de cada provedor de storage. Drivers CSI s√£o instalados como DaemonSets e controlam a cria√ß√£o, montagem e desmontagem de volumes. Isso permite suporte a solu√ß√µes como EBS, GCP PD, Ceph, entre outros.

**Exemplo Manifesto CSI (trecho):**
```yaml
apiVersion: storage.k8s.io/v1
kind: CSIDriver
metadata:
  name: ebs.csi.aws.com
spec:
  attachRequired: true
```

**Refer√™ncias:**
- [Kubernetes CSI Docs](https://kubernetes.io/docs/concepts/storage/volumes/#csi)
- [CSI Spec](https://github.com/container-storage-interface/spec)

---

## üì¶ Volumes

Volumes no Kubernetes s√£o recursos que permitem persistir dados al√©m do ciclo de vida de um pod. Eles s√£o montados nos cont√™ineres e podem ser de tipos diferentes: `emptyDir` (tempor√°rio), `hostPath` (diret√≥rio do host), `nfs`, `configMap`, `secret`, `persistentVolumeClaim` entre outros. A principal vantagem √© que os volumes sobrevivem a reinicializa√ß√µes de cont√™ineres dentro do mesmo pod.

**Exemplo:**
```yaml
apiVersion: v1
kind: Pod
metadata:
  name: pod-com-volume
spec:
  containers:
    - name: app
      image: nginx
      volumeMounts:
        - name: meu-volume
          mountPath: /usr/share/nginx/html
  volumes:
    - name: meu-volume
      emptyDir: {}
```

**Refer√™ncias:**
- [Kubernetes Volumes](https://kubernetes.io/docs/concepts/storage/volumes/)

---

## 9.4 üóÑÔ∏è Persistent Volumes (PV)

Um **Persistent Volume (PV)** √© um recurso do cluster que representa um peda√ßo de armazenamento f√≠sico ou l√≥gico provisionado. PVs s√£o independentes do ciclo de vida de pods e s√£o definidos pelo administrador ou provisionados dinamicamente. Podem usar diversos backends como NFS, iSCSI, AWS EBS, Azure Disk, etc. PVs t√™m um ciclo de vida pr√≥prio e podem ter pol√≠ticas de `Retain`, `Delete` ou `Recycle`. Eles s√£o fundamentais para ambientes produtivos onde dados n√£o podem ser perdidos.

**Exemplo PV:**
```yaml
apiVersion: v1
kind: PersistentVolume
metadata:
  name: pv-nfs
spec:
  capacity:
    storage: 10Gi
  accessModes:
    - ReadWriteMany
  nfs:
    path: /exports/data
    server: 192.168.1.100
  persistentVolumeReclaimPolicy: Retain
```

**Refer√™ncias:**
- [Persistent Volumes](https://kubernetes.io/docs/concepts/storage/persistent-volumes/)

---

## 9.5 üìú Persistent Volume Claims (PVC)

Um **Persistent Volume Claim (PVC)** √© uma solicita√ß√£o feita por um usu√°rio para consumir armazenamento de um PV. Ele especifica o tamanho e o modo de acesso desejado. O Kubernetes tenta ligar (bind) o PVC a um PV compat√≠vel. A diferen√ßa chave √© que **PV √© o recurso f√≠sico ou l√≥gico**, enquanto **PVC √© o pedido de uso**. Se n√£o houver PV adequado, o PVC fica em estado "Pending" at√© que um volume compat√≠vel seja disponibilizado.

**Exemplo PVC:**
```yaml
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: pvc-nfs
spec:
  accessModes:
    - ReadWriteMany
  resources:
    requests:
      storage: 5Gi
```

**Refer√™ncias:**
- [Persistent Volume Claims](https://kubernetes.io/docs/concepts/storage/persistent-volumes/#persistentvolumeclaims)

---

## 9.6 üìÇ Using PVCs in Pods

Para usar um PVC em um Pod, basta referenci√°-lo dentro da se√ß√£o `volumes`. Assim, o Kubernetes garante que o volume solicitado ser√° montado no cont√™iner. Isso desacopla o pod do detalhe do backend de armazenamento, permitindo maior portabilidade e abstra√ß√£o.

**Exemplo Pod usando PVC:**
```yaml
apiVersion: v1
kind: Pod
metadata:
  name: pod-com-pvc
spec:
  containers:
    - name: app
      image: nginx
      volumeMounts:
        - name: dados
          mountPath: /usr/share/nginx/html
  volumes:
    - name: dados
      persistentVolumeClaim:
        claimName: pvc-nfs
```

**Refer√™ncias:**
- [Using Persistent Volume Claims](https://kubernetes.io/docs/concepts/storage/persistent-volumes/#claims-as-volumes)

---

## 9.7 üè∑Ô∏è Storage Class

Um **StorageClass** define **como volumes s√£o provisionados dinamicamente** no Kubernetes. Ele especifica o provisionador (driver CSI ou in-tree), par√¢metros de configura√ß√£o e pol√≠tica de `reclaim`. Cada PVC pode pedir uma StorageClass espec√≠fica para provisionamento autom√°tico de PVs. Sem uma StorageClass definida, os PVCs precisam de PVs pr√©-criados manualmente.

**Exemplo StorageClass:**
```yaml
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: sc-rapido
provisioner: kubernetes.io/aws-ebs
parameters:
  type: gp2
reclaimPolicy: Delete
volumeBindingMode: WaitForFirstConsumer
```

---



## 10. Networking no Docker
- O Docker cria por padr√£o a **bridge `docker0`**, conectando containers a uma sub-rede privada com **NAT** para sa√≠da via host.
- **Redes bridge definidas pelo usu√°rio** oferecem isolamento e DNS embutido entre containers na mesma rede (melhor do que a bridge padr√£o).
- **`-p/--publish`** mapeia portas do container para o host (ex.: `-p 8080:80`), diferente do modelo do Kubernetes onde o **Pod tem IP rote√°vel no cluster**.
- Modos **`host`** (container compartilha a stack de rede do host) e **`none`** (sem interface) existem, mas t√™m pouco uso em produ√ß√£o moderna com orquestradores.
- Em contextos de orquestra√ß√£o (Swarm), redes **overlay (VXLAN)** conectam n√≥s distintos; no K8s, isso √© delegado a um **CNI plugin**, n√£o ao Docker.
- O isolamento se d√° via **namespaces** e **veth pairs**; o tr√°fego de sa√≠da usa **iptables (MASQUERADE)** para NAT.
- O DNS entre containers numa bridge usa o **embedded DNS** do Docker; no K8s, o DNS √© provido por **CoreDNS**.
- **Papel no K8s**: Kubernetes n√£o usa ‚ÄúDocker networking‚Äù diretamente; o kubelet invoca **CNI** para configurar a rede do **Pod**.
- Cuidado: publicar portas via Docker **n√£o equivale** a expor workloads no K8s (l√° usamos **Service/Ingress/Gateway**).
- Diagn√≥stico: `docker network inspect`, `ip addr`, `iptables -t nat -S` ajudam a entender fluxo e NAT do host.
- Para estudo: compare **bridge+NAT** (Docker) vs **IP por Pod e roteamento** (K8s/CNI).
- Em ambientes modernos, **container runtime ‚â† plano de rede**: o runtime executa containers, o **CNI configura rede**.

**üîß Exemplos r√°pidos (paralelos no K8s):**
```bash
# Docker ‚Äì redes
docker network ls
docker network inspect bridge
docker run --rm --network bridge -p 8080:80 nginx:alpine

# Kubernetes ‚Äì "equivalente" conceitual: Pod com hostNetwork
kubectl run hostnet --image=nginx:alpine --overrides='{"spec":{"hostNetwork":true}}'
kubectl get pod -o wide hostnet
```

> **‚öñÔ∏è Diferen√ßas-chave**: Docker publica portas no host; **K8s** usa **Service (ClusterIP/NodePort/LoadBalancer)** e **Ingress/Gateway** para entrada. DNS no Docker vem do engine; no K8s, **CoreDNS** e **Service discovery**.

**üìö Refer√™ncias:**
- Kubernetes ‚Äì [Networking (Vis√£o Geral)](https://kubernetes.io/docs/concepts/services-networking/)
- Kubernetes ‚Äì [Container Runtimes](https://kubernetes.io/docs/setup/production-environment/container-runtimes/)
- Docker ‚Äì [Networking Overview](https://docs.docker.com/network/)

---

## 10.1 Pod Networking (Modelo IP-per-Pod)
- **Cada Pod recebe seu pr√≥prio IP** e todas as containers do Pod compartilham **o mesmo namespace de rede** (lo, interfaces, portas).
- Premissa do K8s: **todos os Pods podem se comunicar sem NAT** (pod-to-pod) e com **qualquer Node** do cluster.
- A implementa√ß√£o concreta desse roteamento vem do **CNI plugin** (Calico, Cilium, Flannel, etc.) ‚Äì Kubernetes define o **modelo**, n√£o a tecnologia.
- **Pod IP √© ef√™mero**: rein√≠cios/realoca√ß√£o podem mudar IP; por isso, a comunica√ß√£o est√°vel usa **Services**.
- **kube-proxy** programa regras (iptables/ipvs) para **Service VIPs** apontarem para **Endpoints/EndpointSlices** dos Pods.
- **Node IP ‚â† Pod IP**: tr√°fego pod‚Üîexterno pode passar por NAT/masquerade, conforme pol√≠tica do CNI e rota de sa√≠da.
- **hostNetwork: true** faz o Pod compartilhar a rede do Node (ganha performance, perde isolamento/porta √∫nica por host).
- **NetworkPolicy** controla tr√°fego L3/L4 entre Pods/Namespaces (necessita CNI compat√≠vel); por padr√£o, tudo √© **permitido**.
- **Service types** (ClusterIP/NodePort/LoadBalancer) resolvem exposi√ß√£o interna/externa; **Ingress/Gateway** lida com L7 (HTTP).
- Em **dual-stack**, Pod/Service podem ter **IPv4+IPv6**; requer configura√ß√£o do cluster e do CNI.
- Diagn√≥stico frequente: `kubectl exec` para `ping`, `curl`, `dig` dentro de Pods de teste.
- Performance/lat√™ncia dependem do modo (overlay, eBPF, roteamento BGP, ipvs, etc.) provido pelo CNI.

**üîß Exemplos (comandos √∫teis):**
```bash
kubectl get pods -o wide -A
kubectl run netshoot --image=nicolaka/netshoot -it --rm -- bash
# Dentro do netshoot:
ip addr && ip route && ss -lntp
# Testes:
curl -I http://my-svc.my-ns.svc.cluster.local
```

**‚öñÔ∏è Diferen√ßas importantes:**
- **Pod vs Container**: Pod √© a **unidade de rede/implanta√ß√£o**; containers dentro dele compartilham IP/portas.
- **Pod IP vs Service IP**: Pod IP muda; Service IP √© **est√°vel** para descoberta e balanceamento.

**üìö Refer√™ncias:**
- Kubernetes ‚Äì [Cluster Networking](https://kubernetes.io/docs/concepts/cluster-administration/networking/)
- Kubernetes ‚Äì [Pods](https://kubernetes.io/docs/concepts/workloads/pods/)
- Kubernetes ‚Äì [Services](https://kubernetes.io/docs/concepts/services-networking/service/)

---

## 10.2 CNI no Kubernetes
- **CNI (Container Network Interface)** √© uma especifica√ß√£o/contrato: o kubelet chama **plugins** para **ADD/DEL** interfaces ao ciclo de vida do Pod.
- Os **bin√°rios** dos plugins ficam em `/opt/cni/bin` e as **configs** em `/etc/cni/net.d/` (ordem lexicogr√°fica define qual usar).
- Plugins populares: **Calico** (BGP/roteado), **Cilium** (eBPF), **Flannel** (VXLAN), **Weave Net**; h√° tamb√©m **Multus** (m√∫ltiplas interfaces).
- Fluxo t√≠pico: criar **veth pair**, anexar ao namespace do Pod, configurar **IPAM**, rotas, e pol√≠ticas (quando suportadas).
- **CNI chaining** permite encadear plugins (ex.: uma interface principal + policy plugin).
- **Kubenet** √© legado e limitado; **use um CNI completo** para NetworkPolicy e recursos avan√ßados.
- O **kubelet** n√£o implementa rede; ele **invoca** o CNI e falha a cria√ß√£o do Pod se a configura√ß√£o for inv√°lida.
- Log e troubleshooting: ver logs do CNI (systemd, `/var/log/‚Ä¶`), checar **Node routes**, `ip a`, `ip r`, `tc`, `bpftool` (Cilium).
- Escolha de CNI impacta **encapsulamento, lat√™ncia, MTU, seguran√ßa (policy), observabilidade** e integra√ß√£o com **Cloud Routes/BGP**.
- Em **managed K8s**, alguns CNIs s√£o **gerenciados** (EKS, GKE, AKS); valide **limita√ß√µes** por provedor.
- Plugins de **policy** (Calico, Cilium) implementam NetworkPolicy L3/L4; Cilium adiciona **L7** com eBPF.
- **IPAM** costuma vir integrado ao CNI (host-local, cluster-pools, etc.), mas pode ser externo.

**üîß Comandos/manifests:**
```bash
# Ver diret√≥rios CNI (Node)
ls -l /opt/cni/bin
ls -l /etc/cni/net.d

# Exemplo: instalar CNI (gen√©rico ‚Äì ajuste ao seu cluster)
kubectl apply -f https://raw.githubusercontent.com/flannel-io/flannel/master/Documentation/kube-flannel.yml
```

**‚öñÔ∏è Diferen√ßas-chave:**
- **CNI ‚â† CNM (Docker)**: K8s segue **CNI**; Docker Swarm segue **CNM**/libnetwork.
- **Kubenet vs CNI completo**: kubenet n√£o suporta NetworkPolicy; CNI completo, sim.

**üìö Refer√™ncias:**
- Kubernetes ‚Äì [CNI (Plugins de Rede)](https://kubernetes.io/docs/concepts/extend-kubernetes/compute-storage-net/network-plugins/)
- Projeto CNI ‚Äì [Spec](https://github.com/containernetworking/cni/blob/main/SPEC.md)

---

## 10.3 IPAM (IP Address Management) no K8s
- **IPAM** aloca endere√ßos a Pods/Interfaces; pode ser **host-local** (por Node), **cluster pool** (global) ou **DHCP**, conforme o plugin.
- O **kube-controller-manager** pode anunciar **podCIDR** por Node (dependendo do modo/Cloud provider) para os CNIs consumirem.
- √â cr√≠tico **planejar CIDRs**: **Pod CIDR** (ex.: 10.244.0.0/16) n√£o deve colidir com redes do datacenter/VPC/VNet e **Service CIDR** (ex.: 10.96.0.0/12).
- **Service CIDR** define range para **ClusterIP**; n√£o √© rote√°vel externamente e costuma trafegar via kube-proxy (iptables/ipvs).
- Em **dual-stack**, planeje **ranges IPv4 e IPv6** para Pods e Services; verifique se o CNI suporta.
- **Exaust√£o de IP** causa falha de cria√ß√£o de Pods; monitore consumo por **Namespace/Node** e aumente pools quando poss√≠vel.
- Alguns CNIs (Calico/Cilium) suportam **pools m√∫ltiplos**, sele√ß√£o por **labels**/namespaces, e reservas por **nodes**.
- **MTU** e encapsulamento (VXLAN/Geneve) impactam fragmenta√ß√£o; ajuste para evitar **path MTU issues**.
- **NodeLocal NAT** e **egress gateways** podem alterar origem do tr√°fego (SNAT); aten√ß√£o a **ACLs** externas.
- **Reservas** e **exclus√µes** s√£o √∫teis para interop com appliances/rotas existentes.
- Auditoria: validar **routes** por Node, **arp/nd**, e a converg√™ncia de **BGP/Cloud Routes** conforme o CNI.
- **Teste de esgotamento** controlado em ambiente de dev detecta falhas cedo.

**üîß Comandos √∫teis:**
```bash
# Ver CIDRs de Service e Pod (vari√°vel conforme instala√ß√£o)
kubectl cluster-info
kubectl describe node | egrep -i "podCIDR|podCIDRs"
kubectl get cm -n kube-system kube-proxy -o yaml | grep -i clusterCIDR -n

# Pod de teste + checagem de IP
kubectl run ipamtest --image=busybox:1.35 --restart=Never -- sleep 3600
kubectl get pod ipamtest -o wide
```

**üìö Refer√™ncias:**
- Kubernetes ‚Äì [IPv4/IPv6 Dual-Stack](https://kubernetes.io/docs/concepts/services-networking/dual-stack/)
- Kubernetes ‚Äì [Services](https://kubernetes.io/docs/concepts/services-networking/service/)
- Kubernetes ‚Äì [Network Plugins (IPAM nos CNIs)](https://kubernetes.io/docs/concepts/extend-kubernetes/compute-storage-net/network-plugins/)

---

## 10.4 DNS no Kubernetes
- O cluster fornece DNS interno para **Pods e Services** (padr√£o: `cluster.local`), resolvido pelo **CoreDNS**.
- **Services (ClusterIP)** ganham registros **A** do tipo `svc.ns.svc.cluster.local`; **headless** Services (`clusterIP: None`) publicam **A** por Pod.
- **Pods** ganham **A/AAAA** via headless Service ou registro reverso em alguns setups; para descoberta, prefira Services.
- **Search domains** no `/etc/resolv.conf` do Pod permitem resolver `my-svc` em `my-svc.my-ns.svc.cluster.local`.
- **ndots** influencia como nomes s√£o consultados (muitos dots tentam FQDN primeiro, impactando lat√™ncia).
- **StubDomains** e **upstreamNameservers** podem ser configurados no ConfigMap do CoreDNS (para resolver dom√≠nios externos).
- **NodeLocal DNSCache** melhora lat√™ncia e reduz load do CoreDNS (daemonset local escutando em 169.254.20.10, por ex.).
- Debug: usar imagens como **netshoot** ou **busybox** e ferramentas `dig`, `nslookup`, `getent hosts`.
- O DNS integra-se aos **Services/EndpointSlices**: mudan√ßa de backends n√£o altera o nome ‚Äì aumenta resili√™ncia.
- Aten√ß√£o a **NetworkPolicies** que podem bloquear UDP/TCP 53 entre Pods e CoreDNS.
- **Split-horizon** e reescritas podem ser feitas com plugins do CoreDNS.
- Services `ExternalName` criam **CNAME** para nomes externos (sem VIP/Proxy).

**üîß Exemplos:**
```bash
kubectl run dnsutils --image=registry.k8s.io/e2e-test-images/jessie-dnsutils:1.3 --restart=Never -- sleep 3600
kubectl exec -it dnsutils -- dig A kubernetes.default.svc.cluster.local
kubectl exec -it dnsutils -- nslookup my-svc.my-ns
```

**üìö Refer√™ncias:**
- Kubernetes ‚Äì [DNS for Services and Pods](https://kubernetes.io/docs/concepts/services-networking/dns-pod-service/)
- Kubernetes ‚Äì [Customize DNS](https://kubernetes.io/docs/tasks/administer-cluster/dns-custom-nameservers/)
- Kubernetes ‚Äì [NodeLocal DNSCache](https://kubernetes.io/docs/tasks/administer-cluster/nodelocaldns/)

---

## 10.5 CoreDNS no Kubernetes
- **CoreDNS** roda como **Deployment** em `kube-system` com um **ConfigMap** contendo o **Corefile** (cadeia de plugins).
- Plugin **`kubernetes`** responde por `*.svc.cluster.local` (ou dom√≠nio configurado), lendo Services/Endpoints via API.
- Plugins comuns: `forward` (encaminhar upstream), `cache`, `rewrite`, `ready`, `health`, `prometheus`, `log`.
- **Escalabilidade**: ajustar r√©plicas, `cache` e habilitar **NodeLocal DNSCache**; monitore lat√™ncia e QPS no Prometheus.
- **StubDomains**: encaminham dom√≠nios espec√≠ficos a DNS upstream distintos (ex.: corp.local ‚Üí AD DNS).
- **rewrite** e **template** permitem flexibilizar respostas (cautela para n√£o quebrar discovery de Services).
- **Observabilidade**: m√©tricas em `/metrics` e logs detalhados com o plugin `log`.
- **Resolu√ß√£o externa**: `forward .` para resolvers do cluster/provedor; cuidado com **ndots/search** que podem gerar tentativas excessivas.
- **Seguran√ßa**: considere restringir quem pode editar o ConfigMap do CoreDNS; uma mudan√ßa errada derruba o DNS do cluster.
- **Affinity/Topology**: posicione r√©plicas em n√≥s distintos para evitar SPOF local.
- **Teste/rollback**: altere o ConfigMap e monitore; tenha manifestos versionados para rollback r√°pido.
- **Compatibilidade**: vers√µes do CoreDNS podem variar por distro/gerenciador (EKS/AKS/GKE).

**üîß Manifests/Comandos:**
```bash
# Ver CoreDNS
kubectl -n kube-system get deploy,svc cm | grep -i coredns
kubectl -n kube-system get cm coredns -o yaml

# Exemplo: adicionando stub domain (trecho do Corefile)
# Corefile (parcial)
# .:53 {
#   kubernetes cluster.local in-addr.arpa ip6.arpa {
#     pods insecure
#     fallthrough in-addr.arpa ip6.arpa
#   }
#   forward corp.local 10.0.0.2 10.0.0.3
#   forward . /etc/resolv.conf
#   cache 30
# }
```

**üìö Refer√™ncias:**
- Kubernetes ‚Äì [Customize DNS Service](https://kubernetes.io/docs/tasks/administer-cluster/dns-custom-nameservers/)
- CoreDNS ‚Äì [Plugins](https://coredns.io/plugins/)
- Kubernetes ‚Äì [NodeLocal DNSCache](https://kubernetes.io/docs/tasks/administer-cluster/nodelocaldns/)

---

## 10.6 Ingress (L7 HTTP/HTTPS)
- **Ingress √© um recurso** que define **regras L7** (host/path) para entrada de tr√°fego em Services do cluster.
- √â necess√°rio um **Ingress Controller** (NGINX, HAProxy, Traefik, ingress-gce, etc.); o recurso sozinho **n√£o** faz nada.
- **IngressClass** seleciona o controlador; anota√ß√µes e CRDs variam por implementa√ß√£o (timeouts, rewrites, rate-limit).
- **TLS** pode ser configurado (termina√ß√£o no controller) referenciando **Secrets** com certificados.
- **Canary/blue-green** podem ser feitos com anota√ß√µes/CRDs do controlador (ex.: nginx ingress canary).
- **Limita√ß√µes**: originalmente focado em HTTP/HTTPS; para TCP/UDP use servi√ßos L4 ou CRDs espec√≠ficos do controller.
- **Service vs Ingress**: Service exp√µe Pods; Ingress **roteia** solicita√ß√µes HTTP(S) para um ou mais Services.
- **NodePort/LoadBalancer** ainda s√£o usados para **expor** o Ingress Controller ao exterior.
- Em clusters gerenciados, o controller pode **provisionar** Load Balancers autom√°ticos.
- Observabilidade: m√©tricas e logs do controller; aten√ß√£o a **X-Forwarded-* headers**, sticky sessions, mTLS (se suportado).
- Seguran√ßa: WAF, restri√ß√µes por IP, autentica√ß√£o/OIDC via auth-url (varia por controller).
- Para rotas avan√ßadas/multi-protocolos, considere **Gateway API**.

**üîß Manifesto m√≠nimo:**
```yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: web-ing
  annotations:
    kubernetes.io/ingress.class: nginx
spec:
  tls:
    - hosts: [ "app.example.com" ]
      secretName: app-tls
  rules:
    - host: app.example.com
      http:
        paths:
          - path: /
            pathType: Prefix
            backend:
              service:
                name: web-svc
                port:
                  number: 80
```

**Comandos √∫teis:**
```bash
kubectl get ingress -A
kubectl describe ingress web-ing
kubectl logs -n ingress-nginx deploy/ingress-nginx-controller
```

**üìö Refer√™ncias:**
- Kubernetes ‚Äì [Ingress](https://kubernetes.io/docs/concepts/services-networking/ingress/)
- Kubernetes ‚Äì [IngressClass](https://kubernetes.io/docs/concepts/services-networking/ingress/#ingress-class)

---

## 10.7 Gateway API (Sucessor evolutivo do Ingress)
- **Gateway API** √© um conjunto de APIs (CRDs) pensado para **expressividade, portabilidade e separa√ß√£o de responsabilidades**.
- Recursos principais: **GatewayClass** (classe do provedor), **Gateway** (data plane/entradas), **HTTPRoute/TCPRoute/UDPRoute/GRPCRoute** (regras).
- **Multi-tenant**: permite **binding** de rotas a Gateways em **namespaces distintos**, com pol√≠ticas de aprova√ß√£o.
- **Listeners** em Gateway definem **portas, protocolos, TLS**, SNI e pol√≠ticas; m√∫ltiplos **Routes** podem anexar-se a um listener.
- **Status/Conditions** ricos facilitam troubleshooting e automa√ß√£o (quem aceitou o qu√™, por qu√™).
- Suporta **TLS**, **mTLS**, pol√≠ticas de **retry**, **time-outs**, **header mods**, **traffic splitting** (conforme controlador).
- **Ingress vs Gateway API**: Ingress √© mais simples e amplamente suportado; Gateway API √© **mais rico** e modular.
- Controladores de refer√™ncia: **GKE/Gateway**, **Istio**, **Contour/Envoy**, **Kong**, **NGINX** (variando recursos suportados).
- **Gradual rollout**: √© poss√≠vel migrar rotas HTTP do Ingress para **HTTPRoute** mantendo equival√™ncia.
- **Pol√≠ticas adicionais** (RateLimit, Authn/Authz) surgem como **Policy APIs** que estendem rotas/gateways.
- **Observabilidade**: integra bem com m√©tricas/telemetria (Envoy/Istio) e status condicionais.
- **Automa√ß√£o**: separa pap√©is ‚Äì plataforma cria **Gateway**, times de app gerenciam **Routes**.
- **Compatibilidade**: verifique a **implementa√ß√£o** do seu provedor ‚Äì nem tudo √© GA em todos os ambientes.

**üîß Manifesto de exemplo (HTTPRoute + Gateway):**
```yaml
apiVersion: gateway.networking.k8s.io/v1
kind: Gateway
metadata:
  name: bank-gw
spec:
  gatewayClassName: nginx
  listeners:
  - name: https
    protocol: HTTPS
    port: 443
    tls:
      mode: Terminate
      certificateRefs:
      - name: bank-tls
---
apiVersion: gateway.networking.k8s.io/v1
kind: HTTPRoute
metadata:
  name: app-route
spec:
  parentRefs:
  - name: bank-gw
  hostnames: ["app.example.com"]
  rules:
  - matches:
    - path:
        type: PathPrefix
        value: /
    backendRefs:
    - name: web-svc
      port: 80
```

**Comandos √∫teis:**
```bash
kubectl get gatewayclasses.gateway.networking.k8s.io
kubectl get gateways,gateway,httproutes -A
kubectl describe httproute app-route
```

**üìö Refer√™ncias:**
- Kubernetes ‚Äì [Gateway API (Vis√£o Geral)](https://kubernetes.io/docs/concepts/services-networking/gateway/)
- Projeto ‚Äì [Gateway API Docs](https://gateway-api.sigs.k8s.io/)
- Kubernetes ‚Äì [Ingress vs Gateway](https://kubernetes.io/docs/concepts/services-networking/gateway/#comparison-with-ingress)

---

### üß≠ Dicas de prova & troubleshooting
> **Use sempre um Pod de utilidades** (ex.: `nicolaka/netshoot`): `curl`, `dig`, `ss`, `tcpdump` ajudam a diagnosticar DNS, rotas, lat√™ncia e pol√≠tica.  
> **Valide objetos** com `kubectl describe` e **eventos** do namespace; inspecione logs do **kube-proxy**, **Ingress/Gateway controllers** e **CoreDNS**.

---

### üìë Tabela express de comandos √∫teis
| Tema | Comandos |
|------|----------|
| Pod Net | `kubectl get pods -o wide -A` ¬∑ `kubectl exec -it <pod> -- ip a` ¬∑ `ip route` |
| DNS/CoreDNS | `kubectl -n kube-system get deploy coredns` ¬∑ `kubectl exec -it dnsutils -- dig ...` |
| CNI | `ls /opt/cni/bin` ¬∑ `ls /etc/cni/net.d` ¬∑ `kubectl get daemonset -A | grep -i cni` |
| Services | `kubectl get svc -A` ¬∑ `kubectl describe svc` ¬∑ `kubectl get endpointslices -A` |
| Ingress | `kubectl get ingress -A` ¬∑ `kubectl logs -n ingress-nginx deploy/ingress-nginx-controller` |
| Gateway API | `kubectl get gateway,httproute -A` ¬∑ `kubectl describe gateway <name>` |

---


